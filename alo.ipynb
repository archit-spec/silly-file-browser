{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "board = [[i,j] for i in range(1,10) for j in range(i,i+10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1],\n",
       " [1, 2],\n",
       " [1, 3],\n",
       " [1, 4],\n",
       " [1, 5],\n",
       " [1, 6],\n",
       " [1, 7],\n",
       " [1, 8],\n",
       " [1, 9],\n",
       " [1, 10],\n",
       " [2, 2],\n",
       " [2, 3],\n",
       " [2, 4],\n",
       " [2, 5],\n",
       " [2, 6],\n",
       " [2, 7],\n",
       " [2, 8],\n",
       " [2, 9],\n",
       " [2, 10],\n",
       " [2, 11],\n",
       " [3, 3],\n",
       " [3, 4],\n",
       " [3, 5],\n",
       " [3, 6],\n",
       " [3, 7],\n",
       " [3, 8],\n",
       " [3, 9],\n",
       " [3, 10],\n",
       " [3, 11],\n",
       " [3, 12],\n",
       " [4, 4],\n",
       " [4, 5],\n",
       " [4, 6],\n",
       " [4, 7],\n",
       " [4, 8],\n",
       " [4, 9],\n",
       " [4, 10],\n",
       " [4, 11],\n",
       " [4, 12],\n",
       " [4, 13],\n",
       " [5, 5],\n",
       " [5, 6],\n",
       " [5, 7],\n",
       " [5, 8],\n",
       " [5, 9],\n",
       " [5, 10],\n",
       " [5, 11],\n",
       " [5, 12],\n",
       " [5, 13],\n",
       " [5, 14],\n",
       " [6, 6],\n",
       " [6, 7],\n",
       " [6, 8],\n",
       " [6, 9],\n",
       " [6, 10],\n",
       " [6, 11],\n",
       " [6, 12],\n",
       " [6, 13],\n",
       " [6, 14],\n",
       " [6, 15],\n",
       " [7, 7],\n",
       " [7, 8],\n",
       " [7, 9],\n",
       " [7, 10],\n",
       " [7, 11],\n",
       " [7, 12],\n",
       " [7, 13],\n",
       " [7, 14],\n",
       " [7, 15],\n",
       " [7, 16],\n",
       " [8, 8],\n",
       " [8, 9],\n",
       " [8, 10],\n",
       " [8, 11],\n",
       " [8, 12],\n",
       " [8, 13],\n",
       " [8, 14],\n",
       " [8, 15],\n",
       " [8, 16],\n",
       " [8, 17],\n",
       " [9, 9],\n",
       " [9, 10],\n",
       " [9, 11],\n",
       " [9, 12],\n",
       " [9, 13],\n",
       " [9, 14],\n",
       " [9, 15],\n",
       " [9, 16],\n",
       " [9, 17],\n",
       " [9, 18]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "snakes = {12: 1,23: 2,53: 4,12: 5, \"allah\": \"a\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinkedList:\n",
    "    def __init__(self, sizee):\n",
    "        sizee = self.sizee\n",
    "    \n",
    "    def node():\n",
    "        pass\n",
    "        \n",
    "\n",
    "class Node(LinkedList):\n",
    "    def bittenbysnake(self, pos):\n",
    "        if self.pos in snakes:\n",
    "            self.pos = snakes.get(self.pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snakes.get(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'Maintain grow election. True spend speak system owner.\\nToday old agreement. Relationship down left month network teach item force.', 'response': 'House follow exactly be sense traditional. Understand after themselves end production physical central. Action body low religious.'}\n",
      "{'query': 'Matter wide field truth both require last. Nice their pass mouth.\\nCover wall act later movie.\\nPosition action week upon popular.\\nTry phone foot huge.', 'response': 'Begin candidate night.\\nCompany expect character recognize black. Structure wide third teacher house. Really might sell second.\\nMore in miss become determine. Up oil oil surface.'}\n",
      "{'query': 'Find floor kind office. Once low either.\\nAgreement suggest during old decide them. Improve hundred trial always sign. Might authority win skin remember require.', 'response': 'Per sound ground. Cost training sit manage.\\nHit positive society enter. Medical operation crime his. Sort example laugh positive involve.\\nRemain family per open. White central make TV.'}\n",
      "{'query': 'Stand citizen clearly good. Cause stop treatment physical focus partner effect. Cause decade that eat.\\nLanguage health picture time. Set night likely page look any that.', 'response': 'Woman north call sister evidence. True drive dinner before heavy once away. Whose reality happy.\\nMemory PM cut room. Above onto small meet add firm plan.'}\n",
      "{'query': 'Above reach behind strong control friend. Remain control discuss direction. Than item girl why music ago.\\nChallenge election water past. Public Democrat pass specific can structure activity lay.', 'response': 'Morning whose new great lose energy. Everything detail argue.\\nBill care entire leader. I camera history rather board recent.'}\n",
      "{'query': 'Amount hour themselves your western class she. Everyone fight poor grow thing mouth.\\nManager image people number boy. How style thought believe child.', 'response': 'Eye throw with responsibility. South particularly population material than nor. Yourself front group method.'}\n",
      "{'query': 'Cost spring business maybe.\\nType ask remember lay know pass single. Fine lay notice order skill leader. Society research benefit spring improve any appear.', 'response': 'Upon easy many style like actually send. Concern late growth song improve wrong yeah. These available agree although great.'}\n",
      "{'query': 'Deep back our maintain inside. Including make international future site who can.\\nOrder account letter until share wonder. Truth democratic painting audience require agreement easy true.', 'response': 'Above structure little series. Sometimes the national along. Sometimes debate Congress start evening past our.\\nAway both theory instead laugh. Figure recent kind could month.'}\n",
      "{'query': 'Say later interesting worry about person. Campaign section fish summer. Start six American former coach buy.', 'response': 'Billion million new paper themselves style. Audience country fact military market and. White all gas property job man.'}\n",
      "{'query': 'Source figure one. Close meeting region real allow fill serve.\\nMiss notice bank low go most. Board table program senior interview politics wide.', 'response': 'Determine admit leg dark suggest administration past. Force view main agree. Laugh cell down know.'}\n"
     ]
    }
   ],
   "source": [
    "from faker import Faker\n",
    "\n",
    "# Create an instance of the Faker class\n",
    "faker = Faker()\n",
    "\n",
    "# Define a schema with text fields\n",
    "schema = {\n",
    "    'query': 'text',\n",
    "    'response': 'text',\n",
    "}\n",
    "\n",
    "# Generate synthetic data based on the schema\n",
    "def generate_data(schema, num_records):\n",
    "    data = []\n",
    "    for _ in range(num_records):\n",
    "        record = {}\n",
    "        for field, field_type in schema.items():\n",
    "            if field_type == 'text':\n",
    "                record[field] = faker.text()\n",
    "        data.append(record)\n",
    "    return data\n",
    "\n",
    "# Generate 10 synthetic records based on the schema\n",
    "synthetic_data = generate_data(schema, 10)\n",
    "\n",
    "# Print the synthetic data\n",
    "for record in synthetic_data:\n",
    "    print(record)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "ture\n",
      "1\n",
      "ture\n"
     ]
    }
   ],
   "source": [
    "a = [[1,2,3,4], [6,7,8,9],[10,11,12,13]]\n",
    "for i in range(0,len(a)-1):\n",
    "    print(i)\n",
    "    if  a[i][-1] - a[i+1][0] !=0:\n",
    "        print('ture')\n",
    "    else:\n",
    "        print('false')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:][1] < a[:][-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval('111 ^  11')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2201"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(str(eval('1101 + 1100')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2201"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(str(eval(str(eval('1101 + 1100')))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dsasds\n"
     ]
    }
   ],
   "source": [
    "print(\"%.6s\" % \"dsasdsa\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 10  # Number of input features\n",
    "hidden_size = 20  # Number of neurons in the hidden layer\n",
    "num_classes = 2  # Number of output classes\n",
    "model = MyModel(input_size, hidden_size, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.Tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "batch_size = 10\n",
    "input_size = 5\n",
    "\n",
    "# Generate random input tensor\n",
    "inputs = torch.randn(batch_size, input_size)\n",
    "\n",
    "# Generate random label tensor\n",
    "labels = torch.randn(batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7313920855522156, 0.7314133644104004, 0.7312718033790588, 0.7306568622589111]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the neural network class\n",
    "class MyNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MyNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "# Specify the input size, hidden size, and output size\n",
    "input_size = 10  # Number of input features\n",
    "hidden_size = 20  # Number of neurons in the hidden layer\n",
    "output_size = 1  # Number of output classes (assuming regression)\n",
    "\n",
    "# Create an instance of the network\n",
    "model = MyNetwork(input_size, hidden_size, output_size)\n",
    "\n",
    "# Define the input data and labels\n",
    "inputs = torch.randn(100, input_size)  # Random input tensor with shape [batch_size, input_size]\n",
    "labels = torch.randn(100, output_size)  # Random label tensor with shape [batch_size, output_size]\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.7)\n",
    "\n",
    "# Lists to store the training and validation loss values\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 5000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    # Compute the loss\n",
    "    loss = loss_function(outputs, labels)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Compute validation loss (dummy example, replace with actual validation)\n",
    "    val_outputs = model(inputs)\n",
    "    val_loss = loss_function(val_outputs, labels)\n",
    "    \n",
    "    # Append the training and validation loss values to the lists\n",
    "    train_losses.append(loss.item())\n",
    "    val_losses.append(val_loss.item())\n",
    "\n",
    "# Plot the training and validation loss\n",
    "plt.plot(range(num_epochs), train_losses, label='Train Loss')\n",
    "plt.plot(range(num_epochs), val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "print(train_losses[-5:-1])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Assuming your trained model is stored in the variable `model`\n",
    "model_path = \"models/model.pt\"\n",
    "torch.save(model.state_dict(), model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "# Load the saved model state dictionary\n",
    "model_path = \"models/model.pt\"\n",
    "model.load_state_dict(torch.load(model_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `input_data` contains your new input data\n",
    "output = model(torch.randn(100, input_size) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement opencv (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for opencv\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcv2\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# Open the default camera\u001b[39;00m\n\u001b[1;32m      4\u001b[0m cap \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mVideoCapture(\u001b[39m0\u001b[39m)  \u001b[39m# 0 represents the first camera device\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Open the default camera\n",
    "cap = cv2.VideoCapture(0)  # 0 represents the first camera device\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the camera\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('Camera', frame)\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the camera and close the window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import llama_cpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama.cpp: loading model from ../../llama-7b.ggmlv3.q2_K.bin\n",
      "llama_model_load_internal: format     = ggjt v3 (latest)\n",
      "llama_model_load_internal: n_vocab    = 32000\n",
      "llama_model_load_internal: n_ctx      = 512\n",
      "llama_model_load_internal: n_embd     = 4096\n",
      "llama_model_load_internal: n_mult     = 256\n",
      "llama_model_load_internal: n_head     = 32\n",
      "llama_model_load_internal: n_layer    = 32\n",
      "llama_model_load_internal: n_rot      = 128\n",
      "llama_model_load_internal: freq_base  = 10000.0\n",
      "llama_model_load_internal: freq_scale = 1\n",
      "llama_model_load_internal: ftype      = 10 (mostly Q2_K)\n",
      "llama_model_load_internal: n_ff       = 11008\n",
      "llama_model_load_internal: model size = 7B\n",
      "llama_model_load_internal: ggml ctx size =    0.08 MB\n",
      "llama_model_load_internal: mem required  = 4242.13 MB (+ 1026.00 MB per state)\n",
      "llama_new_context_with_model: kv self size  =  256.00 MB\n",
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "llm = Llama(\"../../llama-7b.ggmlv3.q2_K.bin\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'cmpl-48326861-afed-46b2-b64c-077e7deeea53', 'object': 'text_completion', 'created': 1689779301, 'model': '../../llama-7b.ggmlv3.q2_K.bin', 'choices': [{'text': \"Q:Opera refers to a dramatic art form, originating in Europe, in which the emotional content is conveyed to the audience as much through music, both vocal and instrumental, as it is through the lyrics. By contrast, in musical theater an actor's dramatic performance is primary, and the music plays a lesser role. The drama in opera is presented using the primary elements of theater such as scenery, costumes, and acting. However, the words of the opera, or libretto, are sung rather than spoken. The singers are accompanied by a musical ensemble ranging from a small instrumental ensemble to a full symphonic orchestra.\\n\\n\\n1. It is pointed out in the reading that opera ----.  A:  Opera refers to a dramatic art form, originating in Europe, in which the emotional content is conveyed to the audience as much through music, both vocal and instrumental, as it is through the lyrics. By contrast, in musical theatre an actor's dramatic performance is primary, and the music plays a lesser role.\", 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 164, 'completion_tokens': 71, 'total_tokens': 235}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time = 27530.71 ms\n",
      "llama_print_timings:      sample time =    61.20 ms /    71 runs   (    0.86 ms per token,  1160.21 tokens per second)\n",
      "llama_print_timings: prompt eval time = 27530.47 ms /   164 tokens (  167.87 ms per token,     5.96 tokens per second)\n",
      "llama_print_timings:        eval time = 16302.07 ms /    70 runs   (  232.89 ms per token,     4.29 tokens per second)\n",
      "llama_print_timings:       total time = 44079.87 ms\n"
     ]
    }
   ],
   "source": [
    "output = llm(\"\"\"Q:Opera refers to a dramatic art form, originating in Europe, in which the emotional content is conveyed to the audience as much through music, both vocal and instrumental, as it is through the lyrics. By contrast, in musical theater an actor's dramatic performance is primary, and the music plays a lesser role. The drama in opera is presented using the primary elements of theater such as scenery, costumes, and acting. However, the words of the opera, or libretto, are sung rather than spoken. The singers are accompanied by a musical ensemble ranging from a small instrumental ensemble to a full symphonic orchestra.\n",
    "\n",
    "\n",
    "1. It is pointed out in the reading that opera ----.  A: \"\"\", max_tokens=1000, stop=[\"Q:\", \"\\n\"], echo=True)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': \"Q:Opera refers to a dramatic art form, originating in Europe, in which the emotional content is conveyed to the audience as much through music, both vocal and instrumental, as it is through the lyrics. By contrast, in musical theater an actor's dramatic performance is primary, and the music plays a lesser role. The drama in opera is presented using the primary elements of theater such as scenery, costumes, and acting. However, the words of the opera, or libretto, are sung rather than spoken. The singers are accompanied by a musical ensemble ranging from a small instrumental ensemble to a full symphonic orchestra.\\n\\n\\n1. It is pointed out in the reading that opera ----.  A:  Opera refers to a dramatic art form, originating in Europe, in which the emotional content is conveyed to the audience as much through music, both vocal and instrumental, as it is through the lyrics. By contrast, in musical theatre an actor's dramatic performance is primary, and the music plays a lesser role.\",\n",
       "  'index': 0,\n",
       "  'logprobs': None,\n",
       "  'finish_reason': 'stop'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.get('choices')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2205.50 ms\n",
      "llama_print_timings:      sample time =    13.66 ms /    17 runs   (    0.80 ms per token,  1244.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3420.78 ms /    18 tokens (  190.04 ms per token,     5.26 tokens per second)\n",
      "llama_print_timings:        eval time =  3712.58 ms /    16 runs   (  232.04 ms per token,     4.31 tokens per second)\n",
      "llama_print_timings:       total time =  7190.09 ms\n"
     ]
    }
   ],
   "source": [
    "output = llm(\"Question: you are a music connoisuer and have great knowledge in contemporary music give me the list of best albums in the world  Music connoiseur: \", max_tokens=1000, stop=[\"Q:\", \"\\n\"], echo=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'Question: you are a music connoisuer and have great knowledge in contemporary music give me the list of best albums in the world  Music connoiseur: 1. Muse – The Origin Of Symmetry (1998)',\n",
       "  'index': 0,\n",
       "  'logprobs': None,\n",
       "  'finish_reason': 'stop'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.get('choices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import LlamaCpp, GPT4All\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'callback_manager' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Make sure the model path is correct for your system!\u001b[39;00m\n\u001b[1;32m      2\u001b[0m llm \u001b[39m=\u001b[39m LlamaCpp(\n\u001b[1;32m      3\u001b[0m     model_path\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m../../llama-7b.ggmlv3.q2_K.bin\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     \u001b[39minput\u001b[39m\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mtemperature\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m0.75\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmax_length\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m2000\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtop_p\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m1\u001b[39m},\n\u001b[0;32m----> 5\u001b[0m     callback_manager\u001b[39m=\u001b[39mcallback_manager,\n\u001b[1;32m      6\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      8\u001b[0m prompt \u001b[39m=\u001b[39m prompt \u001b[39m=\u001b[39m \u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[39mQuestion: explain go programming language\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[39m\"\"\"\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'callback_manager' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Make sure the model path is correct for your system!\n",
    "llm = LlamaCpp(\n",
    "    model_path=\"../../llama-7b.ggmlv3.q2_K.bin\",\n",
    "    input={\"temperature\": 0.75, \"max_length\": 2000, \"top_p\": 1},\n",
    "    callback_manager=callback_manager,\n",
    "    verbose=True,\n",
    ")\n",
    "prompt = prompt = \"\"\"\n",
    "Question: explain go programming language\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'llm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m prompt \u001b[39m=\u001b[39m \u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[39mQuestion: explain go programming language\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[39m\"\"\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m llm(prompt)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'llm' is not defined"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Question: explain go programming language\n",
    "\"\"\"\n",
    "llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nQuestion: A rap battle between Stephen Colbert and John Oliver\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LlamaCpp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m \u001b[39mimport\u001b[39;00m PromptTemplate, OpenAI, LLMChain\n\u001b[1;32m      3\u001b[0m prompt_template \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mWhat is a good name for a company that makes \u001b[39m\u001b[39m{product}\u001b[39;00m\u001b[39m?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m llm \u001b[39m=\u001b[39m LlamaCpp(model_path\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m../../llama-7b.ggmlv3.q2_K.bin\u001b[39m\u001b[39m\"\u001b[39m, callback_manager\u001b[39m=\u001b[39mcallback_manager, verbose\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m llm_chain \u001b[39m=\u001b[39m LLMChain(\n\u001b[1;32m      7\u001b[0m     llm\u001b[39m=\u001b[39mllm,\n\u001b[1;32m      8\u001b[0m     prompt\u001b[39m=\u001b[39mPromptTemplate\u001b[39m.\u001b[39mfrom_template(prompt_template)\n\u001b[1;32m      9\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LlamaCpp' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate, OpenAI, LLMChain\n",
    "\n",
    "prompt_template = \"What is a good name for a company that makes {product}?\"\n",
    "\n",
    "llm = LlamaCpp(model_path=\"../../llama-7b.ggmlv3.q2_K.bin\", callback_manager=callback_manager, verbose=True)\n",
    "llm_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=PromptTemplate.from_template(prompt_template)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama.cpp: loading model from ../../llama-7b.ggmlv3.q2_K.bin\n",
      "llama_model_load_internal: format     = ggjt v3 (latest)\n",
      "llama_model_load_internal: n_vocab    = 32000\n",
      "llama_model_load_internal: n_ctx      = 512\n",
      "llama_model_load_internal: n_embd     = 4096\n",
      "llama_model_load_internal: n_mult     = 256\n",
      "llama_model_load_internal: n_head     = 32\n",
      "llama_model_load_internal: n_layer    = 32\n",
      "llama_model_load_internal: n_rot      = 128\n",
      "llama_model_load_internal: freq_base  = 10000.0\n",
      "llama_model_load_internal: freq_scale = 1\n",
      "llama_model_load_internal: ftype      = 10 (mostly Q2_K)\n",
      "llama_model_load_internal: n_ff       = 11008\n",
      "llama_model_load_internal: model size = 7B\n",
      "llama_model_load_internal: ggml ctx size =    0.08 MB\n",
      "llama_model_load_internal: mem required  = 4242.13 MB (+ 1026.00 MB per state)\n",
      "llama_new_context_with_model: kv self size  =  256.00 MB\n",
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "llm = LlamaCpp(model_path=\"../../llama-7b.ggmlv3.q2_K.bin\", callback_manager=callback_manager, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "tools = load_tools([\"google-serper\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.utilities import GoogleSerperAPIWrapper\n",
    "from langchain.utilities import GoogleSerperAPIWrapper\n",
    "from langchain.llms.openai import OpenAI\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.agents import AgentType\n",
    "os.environ[\"SERPER_API_KEY\"] = \"ac7b16b8b759d5365229f0c43fe6c94cbc2ca852b3ab116edcd1224f6160a5a5\"\n",
    "search = GoogleSerperAPIWrapper()\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Intermediate Answer\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to ask with search\"\n",
    "    )\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama.cpp: loading model from ../../llama-7b.ggmlv3.q2_K.bin\n",
      "llama_model_load_internal: format     = ggjt v3 (latest)\n",
      "llama_model_load_internal: n_vocab    = 32000\n",
      "llama_model_load_internal: n_ctx      = 512\n",
      "llama_model_load_internal: n_embd     = 4096\n",
      "llama_model_load_internal: n_mult     = 256\n",
      "llama_model_load_internal: n_head     = 32\n",
      "llama_model_load_internal: n_layer    = 32\n",
      "llama_model_load_internal: n_rot      = 128\n",
      "llama_model_load_internal: freq_base  = 10000.0\n",
      "llama_model_load_internal: freq_scale = 1\n",
      "llama_model_load_internal: ftype      = 10 (mostly Q2_K)\n",
      "llama_model_load_internal: n_ff       = 11008\n",
      "llama_model_load_internal: model size = 7B\n",
      "llama_model_load_internal: ggml ctx size =    0.08 MB\n",
      "llama_model_load_internal: mem required  = 4242.13 MB (+ 1026.00 MB per state)\n",
      "llama_new_context_with_model: kv self size  =  256.00 MB\n",
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "from langchain import OpenAI, LLMChain, PromptTemplate\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "template = \"\"\"Assistant is a large language model trained by tammu.\n",
    "\n",
    "Assistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
    "\n",
    "Assistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
    "\n",
    "Overall, Assistant is a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\n",
    "\n",
    "Assistant is aware that human input is being transcribed from audio and as such there may be some errors in the transcription. It will attempt to account for some words being swapped with similar-sounding words or phrases. Assistant will also keep responses concise, because human attention spans are more limited over the audio channel since it takes time to listen to a response.\n",
    "\n",
    "{history}\n",
    "Human: {human_input}\n",
    "Assistant:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(input_variables=[\"history\", \"human_input\"], template=template)\n",
    "\n",
    "\n",
    "chatgpt_chain = LLMChain(\n",
    "    llm = LlamaCpp(model_path=\"../../llama-7b.ggmlv3.q2_K.bin\", callback_manager=callback_manager, verbose=True),\n",
    "    prompt=prompt,\n",
    "    verbose=True,\n",
    "    memory=ConversationBufferWindowMemory(k=2),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/dumball/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/dumball/nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d1: ['romeo', 'juliet']\n",
      "d2: ['juliet', 'happi', 'dagger']\n",
      "d3: ['romeo', 'die', 'dagger']\n",
      "d4: ['live', 'free', 'die', 'motto']\n",
      "d5: ['know', 'new', 'england']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Sample documents\n",
    "documents = [\n",
    "    \"romeo and juliet\",\n",
    "    \"juliet: o happy dagger!\",\n",
    "    \"romeo died by dagger.\",\n",
    "    \"Live free or die, that's the new-hampshire's motto.\",\n",
    "    \"did you know, New-hampshire is in new england\"\n",
    "]\n",
    "\n",
    "# Tokenization and lowercasing\n",
    "nltk.download('punkt')  # Download the punkt tokenizer if you haven't already\n",
    "nltk.download('stopwords')  # Download stopwords if you haven't already\n",
    "stop_words = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()\n",
    "\n",
    "tokenized_documents = []\n",
    "for doc in documents:\n",
    "    words = word_tokenize(doc.lower())  # Tokenization and lowercasing\n",
    "    filtered_words = [ps.stem(word) for word in words if word.isalnum() and word not in stop_words]  # Stemming and stop word removal\n",
    "    tokenized_documents.append(filtered_words)\n",
    "\n",
    "# Print the tokenized and processed documents\n",
    "for i, tokens in enumerate(tokenized_documents):\n",
    "    print(f\"d{i + 1}: {tokens}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Obtaining dependency information for gensim from https://files.pythonhosted.org/packages/e8/d9/104988573fd2c1acdc64e66883b35fb8ae559310d2d9f77db78bf7de9add/gensim-4.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading gensim-4.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: numpy>=1.18.5 in ./env/lib/python3.10/site-packages (from gensim) (1.26.0)\n",
      "Requirement already satisfied: scipy>=1.7.0 in ./env/lib/python3.10/site-packages (from gensim) (1.11.1)\n",
      "Collecting smart-open>=1.8.1 (from gensim)\n",
      "  Obtaining dependency information for smart-open>=1.8.1 from https://files.pythonhosted.org/packages/fc/d9/d97f1db64b09278aba64e8c81b5d322d436132df5741c518f3823824fae0/smart_open-6.4.0-py3-none-any.whl.metadata\n",
      "  Downloading smart_open-6.4.0-py3-none-any.whl.metadata (21 kB)\n",
      "Downloading gensim-4.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.5/26.5 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading smart_open-6.4.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: smart-open, gensim\n",
      "Successfully installed gensim-4.3.2 smart-open-6.4.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: (0, '-0.340*\"17\" + -0.340*\"14\" + -0.340*\"11\" + -0.340*\"10\" + -0.340*\"15\" + -0.340*\"16\" + -0.340*\"13\" + -0.340*\"12\" + -0.096*\"22\" + -0.096*\"24\"')\n",
      "Topic 2: (1, '-0.340*\"21\" + -0.340*\"24\" + -0.340*\"23\" + -0.340*\"22\" + -0.340*\"20\" + -0.340*\"25\" + -0.340*\"19\" + -0.340*\"18\" + 0.096*\"17\" + 0.096*\"11\"')\n",
      "LSA representation of the new document:\n",
      "[(0, -0.09592501849155331), (1, -0.3402916261493883)]\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.models import LsiModel\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "# Sample documents\n",
    "documents = [\n",
    "    \"romeo and juliet\",\n",
    "    \"juliet: o happy dagger!\",\n",
    "    \"romeo died by dagger.\",\n",
    "    \"Live free or die, that's the new-hampshire's motto.\",\n",
    "    \"did you know, New-hampshire is in new england\"\n",
    "]\n",
    "\n",
    "# Tokenize and preprocess the documents (assuming you have already tokenized them)\n",
    "tokenized_documents = [doc.split() for doc in documents]\n",
    "\n",
    "# Create a Gensim Dictionary\n",
    "dictionary = Dictionary(tokenized_documents)\n",
    "\n",
    "# Create a document-term matrix\n",
    "corpus = [dictionary.doc2bow(doc) for doc in tokenized_documents]\n",
    "\n",
    "# Perform LSA/LSI using Gensim\n",
    "num_topics = 2  # Number of topics to extract\n",
    "lsi_model = LsiModel(corpus, num_topics=num_topics)\n",
    "\n",
    "# Print the LSA results\n",
    "for i, topic in enumerate(lsi_model.show_topics()):\n",
    "    print(f\"Topic {i + 1}: {topic}\")\n",
    "\n",
    "# Transform a new document into the LSA space\n",
    "new_doc = \"romeo and juliet are characters in a famous play.\"\n",
    "new_doc_bow = dictionary.doc2bow(new_doc.split())\n",
    "new_doc_lsa = lsi_model[new_doc_bow]\n",
    "print(\"LSA representation of the new document:\")\n",
    "print(new_doc_lsa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transforrmers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m AutoTokenizer, pipeline, logging\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mauto_gptq\u001b[39;00m \u001b[39mimport\u001b[39;00m AutoGPTQForCausalLM, BaseQuantizeConfig\n\u001b[1;32m      4\u001b[0m model_name_or_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mTheBloke/Llama-2-13B-chat-GPTQ\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers'"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, pipeline, logging\n",
    "from auto_gptq import AutoGPTQForCausalLM, BaseQuantizeConfig\n",
    "\n",
    "model_name_or_path = \"TheBloke/Llama-2-13B-chat-GPTQ\"\n",
    "model_basename = \"gptq_model-4bit-128g\"\n",
    "\n",
    "use_triton = False\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=True)\n",
    "\n",
    "model = AutoGPTQForCausalLM.from_quantized(model_name_or_path,\n",
    "        model_basename=model_basename,\n",
    "        use_safetensors=True,\n",
    "        trust_remote_code=True,\n",
    "        device=\"cuda:0\",\n",
    "        use_triton=use_triton,\n",
    "        quantize_config=None)\n",
    "\n",
    "\"\"\"\n",
    "To download from a specific branch, use the revision parameter, as in this example:\n",
    "\n",
    "model = AutoGPTQForCausalLM.from_quantized(model_name_or_path,\n",
    "        revision=\"gptq-4bit-32g-actorder_True\",\n",
    "        model_basename=model_basename,\n",
    "        use_safetensors=True,\n",
    "        trust_remote_code=True,\n",
    "        device=\"cuda:0\",\n",
    "        quantize_config=None)\n",
    "\"\"\"\n",
    "\n",
    "prompt = \"Tell me about AI\"\n",
    "prompt_template=f'''[INST] <<SYS>>\n",
    "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature. If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n",
    "<</SYS>>\n",
    "{prompt}[/INST]'''\n",
    "\n",
    "print(\"\\n\\n*** Generate:\")\n",
    "\n",
    "input_ids = tokenizer(prompt_template, return_tensors='pt').input_ids.cuda()\n",
    "output = model.generate(inputs=input_ids, temperature=0.7, max_new_tokens=512)\n",
    "print(tokenizer.decode(output[0]))\n",
    "\n",
    "# Inference can also be done using transformers' pipeline\n",
    "\n",
    "# Prevent printing spurious transformers error when using pipeline with AutoGPTQ\n",
    "logging.set_verbosity(logging.CRITICAL)\n",
    "\n",
    "print(\"*** Pipeline:\")\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=512,\n",
    "    temperature=0.7,\n",
    "    top_p=0.95,\n",
    "    repetition_penalty=1.15\n",
    ")\n",
    "\n",
    "print(pipe(prompt_template)[0]['generated_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
